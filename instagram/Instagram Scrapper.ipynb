{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instagram Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\marku\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\marku\\anaconda3\\lib\\site-packages (from textblob) (3.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\marku\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data from Instagram users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: videos they post.\n",
      "Followers: Follow\n",
      "Following: (@lgbtq)\n",
      "Posts: never\n",
      "---------------------------\n",
      "User: from LGBT (@lgbt)\n",
      "Followers: 529k\n",
      "Following: 88\n",
      "Posts: 378\n",
      "---------------------------\n",
      "User: from Pride (@pride)\n",
      "Followers: 343.1k\n",
      "Following: 85\n",
      "Posts: 320\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import requests\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup     #html parser\n",
    "import ssl\n",
    "import json\n",
    "\n",
    "\n",
    "class Insta_Info_Scraper:\n",
    "\n",
    "    def getinfo(self, url):\n",
    "        html = urllib.request.urlopen(url, context=self.ctx).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        #data = get the information from the tag og:description containing information about followers, posts etc. \n",
    "        data = soup.find_all('meta', attrs={'property': 'og:description'    \n",
    "                             })\n",
    "        text = data[0].get('content').split()\n",
    "        user = '%s %s %s' % (text[-3], text[-2], text[-1])\n",
    "        followers = text[0]\n",
    "        following = text[2]\n",
    "        posts = text[4]\n",
    "        print ('User:', user)\n",
    "        print ('Followers:', followers)\n",
    "        print ('Following:', following)\n",
    "        print ('Posts:', posts)\n",
    "        print ('---------------------------')\n",
    "\n",
    "    def main(self):\n",
    "        self.ctx = ssl.create_default_context()\n",
    "        self.ctx.check_hostname = False\n",
    "        self.ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "        with open('users.txt') as f:\n",
    "            self.content = f.readlines()\n",
    "        self.content = [x.strip() for x in self.content]\n",
    "        for url in self.content:\n",
    "            self.getinfo(url)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    obj = Insta_Info_Scraper()\n",
    "    obj.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading publications (text and pictures) containing some hashtags\n",
    "#### We also calculate the average sentiment of the downloaded publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping links with #LGBTQ...........\n",
      "Avg Subjectivity 0.4280669588592693\n",
      "Avg Polarity 0.2347597646648244\n",
      "Counter 66\n",
      "Scraping links with #LGBT...........\n",
      "Avg Subjectivity 0.517523679865683\n",
      "Avg Polarity 0.2757294348594814\n",
      "Counter 70\n",
      "Scraping links with #lgbtq...........\n",
      "Avg Subjectivity 0.4280669588592693\n",
      "Avg Polarity 0.2347597646648244\n",
      "Counter 66\n",
      "Scraping links with #lgbt...........\n",
      "Avg Subjectivity 0.517523679865683\n",
      "Avg Polarity 0.2757294348594814\n",
      "Counter 70\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import requests\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "class Insta_Image_Links_Scraper:\n",
    "\n",
    "    def getlinks(self, hashtag, url):\n",
    "\n",
    "        cummulative_polarity = 0\n",
    "        cummulative_subjectivity = 0\n",
    "        counter = 0\n",
    "        \n",
    "        html = urllib.request.urlopen(url, context=self.ctx).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        script = soup.find('script', text=lambda t: \\\n",
    "                           t.startswith('window._sharedData'))\n",
    "        page_json = script.text.split(' = ', 1)[1].rstrip(';')\n",
    "        data = json.loads(page_json)\n",
    "        print ('Scraping links with #' + hashtag+\"...........\")\n",
    "        for post in data['entry_data']['TagPage'][0]['graphql'\n",
    "                ]['hashtag']['edge_hashtag_to_media']['edges']:\n",
    "            image_src = post['node']['thumbnail_resources'][1]['src']\n",
    "            if (post['node']['edge_media_to_caption']['edges'] != []):\n",
    "                text = post['node']['edge_media_to_caption']['edges'][0]['node']['text']\n",
    "                #print(text) # text of the post\n",
    "                \n",
    "                # getting the polarity of the sentimentalisis\n",
    "                analysis = TextBlob(text)\n",
    "                polarity = analysis.sentiment[0]\n",
    "                cummulative_polarity += polarity\n",
    "                subjectivity = analysis.sentiment[1]\n",
    "                cummulative_subjectivity += subjectivity\n",
    "                counter += 1\n",
    "            hs = open(hashtag + '.txt', 'a')\n",
    "            hs.write(image_src + '\\n')\n",
    "            hs.close()\n",
    "        if counter != 0:\n",
    "            print ('Avg Subjectivity', cummulative_subjectivity/counter)\n",
    "            print ('Avg Polarity', cummulative_polarity/counter)\n",
    "            print ('Counter', counter)\n",
    "\n",
    "    def main(self):\n",
    "        self.ctx = ssl.create_default_context()\n",
    "        self.ctx.check_hostname = False\n",
    "        self.ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "        with open('hashtag_list.txt') as f:\n",
    "            self.content = f.readlines()\n",
    "        self.content = [x.strip() for x in self.content]\n",
    "        for hashtag in self.content:\n",
    "            self.getlinks(hashtag,\n",
    "                          'https://www.instagram.com/explore/tags/'\n",
    "                          + hashtag + '/')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    obj = Insta_Image_Links_Scraper()\n",
    "    obj.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
