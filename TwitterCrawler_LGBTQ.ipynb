{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Install the twitter library in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Install library for JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user simplejson"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Install sentiment analysis library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever library you use\n",
    "!pip install --user textblob\n",
    "!python -m textblob.download_corpora lite"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming tweets and perform some data analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting up and running a streaming crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import simplejson as json\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete with your keys \n",
    "\n",
    "\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "\n",
    "class MyListener(StreamListener):\n",
    "    \n",
    "    def __init__(self, api=None):\n",
    "        super(StreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            with open('crawled_tweets.json', 'a', newline='') as f:\n",
    "                # Filtering data only with info about the country\n",
    "                if json.loads(data).get('place'): #checks that the attribute exists \n",
    "                    # if json.loads(data)['place']['country'] == target: select specific country = target\n",
    "                    f.write(data) # This will store the whole JSON data in the file, you can perform some JSON filters\n",
    "                    twitter_text = json.loads(data)['text'] # You can also print your tweets here\n",
    "                    self.num_tweets += 1\n",
    "                \n",
    "                # Just to limit the number of tweets collected to check the \n",
    "                # program at the beginning, then increase the limit\n",
    "                if self.num_tweets < 200: \n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    "\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print('Error :', status.place)\n",
    "        return False\n",
    "    \n",
    "twitter_stream = Stream(auth, MyListener())\n",
    "twitter_stream.filter(track=[\"lgbt\", \"LGBT\", \"LGBTQ\", \"lgbtq\", \"lgbtq+\", \"LGBTQ+\"]) # Add your keywords and other filters\n",
    "#twitter_stream.filter(track=['Trump']) # Add your keywords and other\n",
    "print('_______ End _______')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store the JSON data in a CSV for analysing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "\n",
    "# Create the CSV file\n",
    "with open (\"data/LGBTQ_no_country.csv\", 'w', encoding ='utf-8') as csv:\n",
    "    # Write the title of the columns (features) that you want to store in the CSV file\n",
    "    csv.write('id, created_at, followers, friends, favorite_count, verified, description, text\\n')\n",
    "    #country, followers, friends, text\\n')\n",
    "    \n",
    "    # Copy the data from the JSON file\n",
    "    with open('data/LGBTQ_no_country.json', 'r', encoding ='utf-8') as jsonfile:\n",
    "        for tweet in jsonfile: \n",
    "            data = json.loads(tweet)\n",
    "            text = str(data['text'].replace('\\n', '').replace(\",\", \"\"))\n",
    "            id_ = str(data['id'])\n",
    "            created_at = str(data['created_at'])\n",
    "            #country = str(data['place']['country'])\n",
    "            followers = str(data['user']['followers_count'])\n",
    "            friends = str(data['user']['friends_count'])\n",
    "            favorites = str(data['favorite_count'])\n",
    "            verified = str(data['user']['verified'])\n",
    "            description = ''\n",
    "            if(data['user']['description']):\n",
    "                description = str(data['user']['description'].replace('\\n', '').replace(\",\", \"\"))\n",
    "            else: \n",
    "                description = ''\n",
    "            line = id_+','+created_at+','+followers+','+friends+','+favorites+','+verified+','+description+','+text+'\\n'\n",
    "            #country+','+\n",
    "            csv.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the previous CSV into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>followers</th>\n      <th>friends</th>\n      <th>favorite_count</th>\n      <th>verified</th>\n      <th>description</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1218938315472195584</th>\n      <td>Sun Jan 19 16:48:35 +0000 2020</td>\n      <td>957.0</td>\n      <td>1561.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>Lesbian | Insignificant Neoconservative Ideolo...</td>\n      <td>Socialism benefits no one</td>\n    </tr>\n    <tr>\n      <th>1218938318135746562</th>\n      <td>Sun Jan 19 16:48:36 +0000 2020</td>\n      <td>14.0</td>\n      <td>131.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>üê∂</td>\n      <td>@atahasnain53 Sir would you be willing to comm...</td>\n    </tr>\n    <tr>\n      <th>1218938324058103808</th>\n      <td>Sun Jan 19 16:48:37 +0000 2020</td>\n      <td>190.0</td>\n      <td>146.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>Just some bisexual idiot on the Internet. Slut...</td>\n      <td>@satiricole @AllianceLGB A transphobe was kick...</td>\n    </tr>\n    <tr>\n      <th>1218938329124810753</th>\n      <td>Sun Jan 19 16:48:39 +0000 2020</td>\n      <td>368.0</td>\n      <td>1253.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>RT @OwenJones84: The 'LGB Alliance' is a hate ...</td>\n    </tr>\n    <tr>\n      <th>1218938330370519040</th>\n      <td>Sun Jan 19 16:48:39 +0000 2020</td>\n      <td>3829.0</td>\n      <td>4841.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>#Spoonie #NoStigma #NoH8  #LoveWins #RESIST #W...</td>\n      <td>RT @Jersey_Craig: The US Hasn't Only Stopped D...</td>\n    </tr>\n    <tr>\n      <th>1218938346665336834</th>\n      <td>Sun Jan 19 16:48:43 +0000 2020</td>\n      <td>88.0</td>\n      <td>246.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>RT @LozzaFox: Nothing more #stunningandbrave t...</td>\n    </tr>\n    <tr>\n      <th>1218938349265850369</th>\n      <td>Sun Jan 19 16:48:43 +0000 2020</td>\n      <td>718.0</td>\n      <td>1405.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>RT @BrandonStraka: #WalkAway is teaming up wit...</td>\n    </tr>\n    <tr>\n      <th>1218938351337660421</th>\n      <td>Sun Jan 19 16:48:44 +0000 2020</td>\n      <td>296.0</td>\n      <td>403.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>Come Back Soon Woojin üêªüíô</td>\n      <td>RT @kpophappenings_: when that kpop boy played...</td>\n    </tr>\n    <tr>\n      <th>1218938356140331009</th>\n      <td>Sun Jan 19 16:48:45 +0000 2020</td>\n      <td>156.0</td>\n      <td>119.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>23. Professional nerd. Amateur musician. Quest...</td>\n      <td>idk who he is but we stan hard üò§üò§üò§üò§üò§üò§üò§üò§üò§üò§üò§üò§üò§üò§</td>\n    </tr>\n    <tr>\n      <th>1218938357918715906</th>\n      <td>Sun Jan 19 16:48:45 +0000 2020</td>\n      <td>403.0</td>\n      <td>349.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>Je d√©barque dans ta vie en claquettes secondai...</td>\n      <td>@CharlotteThuil3 Mes mains sont lgbtq</td>\n    </tr>\n    <tr>\n      <th>1218938379548725249</th>\n      <td>Sun Jan 19 16:48:51 +0000 2020</td>\n      <td>243.0</td>\n      <td>1105.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>#BARON ; ‚ò∫Ô∏è i‚Äòm the cutest babie alive</td>\n      <td>RT @kpophappenings_: when that kpop boy played...</td>\n    </tr>\n    <tr>\n      <th>1218938380983132162</th>\n      <td>Sun Jan 19 16:48:51 +0000 2020</td>\n      <td>981.0</td>\n      <td>969.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>rachel the anarchist. not a tolerant leftist. ...</td>\n      <td>she is just your version of gun girl. you t e ...</td>\n    </tr>\n    <tr>\n      <th>1218938387857584128</th>\n      <td>Sun Jan 19 16:48:53 +0000 2020</td>\n      <td>1523.0</td>\n      <td>2566.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>Don't blame me I didn't vote for Rahm(Gone)Rau...</td>\n      <td>RT @CTULocal1: CTU/@iftaft members! We're crea...</td>\n    </tr>\n    <tr>\n      <th>1218938389845561345</th>\n      <td>Sun Jan 19 16:48:53 +0000 2020</td>\n      <td>52.0</td>\n      <td>46.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>RT @fantasticleak16: Dear Twitter.You are not ...</td>\n    </tr>\n    <tr>\n      <th>1218938395017142272</th>\n      <td>Sun Jan 19 16:48:54 +0000 2020</td>\n      <td>14.0</td>\n      <td>83.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>Lover of women hater of bullies.</td>\n      <td>@amyklobuchar Senator  I am a woman and a lesb...</td>\n    </tr>\n    <tr>\n      <th>1218938408581640192</th>\n      <td>Sun Jan 19 16:48:58 +0000 2020</td>\n      <td>43.0</td>\n      <td>70.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>@stelinanutshell's backup</td>\n      <td>nsfw 18+ au dom sub sugar daddy mommy lesbian ...</td>\n    </tr>\n    <tr>\n      <th>1218938410964082690</th>\n      <td>Sun Jan 19 16:48:58 +0000 2020</td>\n      <td>296.0</td>\n      <td>35.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>RT @DeltaAndDaisy: Today we march for women's ...</td>\n    </tr>\n    <tr>\n      <th>1218938414122373120</th>\n      <td>Sun Jan 19 16:48:59 +0000 2020</td>\n      <td>2163.0</td>\n      <td>2119.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>#ÏóëÏä§Ïõê + #ÏóêÏù¥Ïä§ + #ÏõêÏñ¥Ïä§ + #Ïä§ÌÇ§Ï¶à ‚Üù all my love for my...</td>\n      <td>RT @kpophappenings_: when that kpop boy played...</td>\n    </tr>\n    <tr>\n      <th>1218938418207563786</th>\n      <td>Sun Jan 19 16:49:00 +0000 2020</td>\n      <td>3619.0</td>\n      <td>3777.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>Transhumanist Future MartianInvisible Bisexual...</td>\n      <td>RT @sazmeister88: if we made politics a less h...</td>\n    </tr>\n    <tr>\n      <th>1218938419608522754</th>\n      <td>Sun Jan 19 16:49:00 +0000 2020</td>\n      <td>32.0</td>\n      <td>80.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>RT @AFNCCF: We're asking #LGBTQ young people a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                         created_at  followers  friends  \\\nid                                                                        \n1218938315472195584  Sun Jan 19 16:48:35 +0000 2020      957.0   1561.0   \n1218938318135746562  Sun Jan 19 16:48:36 +0000 2020       14.0    131.0   \n1218938324058103808  Sun Jan 19 16:48:37 +0000 2020      190.0    146.0   \n1218938329124810753  Sun Jan 19 16:48:39 +0000 2020      368.0   1253.0   \n1218938330370519040  Sun Jan 19 16:48:39 +0000 2020     3829.0   4841.0   \n1218938346665336834  Sun Jan 19 16:48:43 +0000 2020       88.0    246.0   \n1218938349265850369  Sun Jan 19 16:48:43 +0000 2020      718.0   1405.0   \n1218938351337660421  Sun Jan 19 16:48:44 +0000 2020      296.0    403.0   \n1218938356140331009  Sun Jan 19 16:48:45 +0000 2020      156.0    119.0   \n1218938357918715906  Sun Jan 19 16:48:45 +0000 2020      403.0    349.0   \n1218938379548725249  Sun Jan 19 16:48:51 +0000 2020      243.0   1105.0   \n1218938380983132162  Sun Jan 19 16:48:51 +0000 2020      981.0    969.0   \n1218938387857584128  Sun Jan 19 16:48:53 +0000 2020     1523.0   2566.0   \n1218938389845561345  Sun Jan 19 16:48:53 +0000 2020       52.0     46.0   \n1218938395017142272  Sun Jan 19 16:48:54 +0000 2020       14.0     83.0   \n1218938408581640192  Sun Jan 19 16:48:58 +0000 2020       43.0     70.0   \n1218938410964082690  Sun Jan 19 16:48:58 +0000 2020      296.0     35.0   \n1218938414122373120  Sun Jan 19 16:48:59 +0000 2020     2163.0   2119.0   \n1218938418207563786  Sun Jan 19 16:49:00 +0000 2020     3619.0   3777.0   \n1218938419608522754  Sun Jan 19 16:49:00 +0000 2020       32.0     80.0   \n\n                     favorite_count verified  \\\nid                                             \n1218938315472195584             0.0    False   \n1218938318135746562             0.0    False   \n1218938324058103808             0.0    False   \n1218938329124810753             0.0    False   \n1218938330370519040             0.0    False   \n1218938346665336834             0.0    False   \n1218938349265850369             0.0    False   \n1218938351337660421             0.0    False   \n1218938356140331009             0.0    False   \n1218938357918715906             0.0    False   \n1218938379548725249             0.0    False   \n1218938380983132162             0.0    False   \n1218938387857584128             0.0    False   \n1218938389845561345             0.0    False   \n1218938395017142272             0.0    False   \n1218938408581640192             0.0    False   \n1218938410964082690             0.0    False   \n1218938414122373120             0.0    False   \n1218938418207563786             0.0    False   \n1218938419608522754             0.0    False   \n\n                                                           description  \\\nid                                                                       \n1218938315472195584  Lesbian | Insignificant Neoconservative Ideolo...   \n1218938318135746562                                                  üê∂   \n1218938324058103808  Just some bisexual idiot on the Internet. Slut...   \n1218938329124810753                                                NaN   \n1218938330370519040  #Spoonie #NoStigma #NoH8  #LoveWins #RESIST #W...   \n1218938346665336834                                                NaN   \n1218938349265850369                                                NaN   \n1218938351337660421                           Come Back Soon Woojin üêªüíô   \n1218938356140331009  23. Professional nerd. Amateur musician. Quest...   \n1218938357918715906  Je d√©barque dans ta vie en claquettes secondai...   \n1218938379548725249             #BARON ; ‚ò∫Ô∏è i‚Äòm the cutest babie alive   \n1218938380983132162  rachel the anarchist. not a tolerant leftist. ...   \n1218938387857584128  Don't blame me I didn't vote for Rahm(Gone)Rau...   \n1218938389845561345                                                NaN   \n1218938395017142272                   Lover of women hater of bullies.   \n1218938408581640192                          @stelinanutshell's backup   \n1218938410964082690                                                NaN   \n1218938414122373120  #ÏóëÏä§Ïõê + #ÏóêÏù¥Ïä§ + #ÏõêÏñ¥Ïä§ + #Ïä§ÌÇ§Ï¶à ‚Üù all my love for my...   \n1218938418207563786  Transhumanist Future MartianInvisible Bisexual...   \n1218938419608522754                                                NaN   \n\n                                                                  text  \nid                                                                      \n1218938315472195584                          Socialism benefits no one  \n1218938318135746562  @atahasnain53 Sir would you be willing to comm...  \n1218938324058103808  @satiricole @AllianceLGB A transphobe was kick...  \n1218938329124810753  RT @OwenJones84: The 'LGB Alliance' is a hate ...  \n1218938330370519040  RT @Jersey_Craig: The US Hasn't Only Stopped D...  \n1218938346665336834  RT @LozzaFox: Nothing more #stunningandbrave t...  \n1218938349265850369  RT @BrandonStraka: #WalkAway is teaming up wit...  \n1218938351337660421  RT @kpophappenings_: when that kpop boy played...  \n1218938356140331009      idk who he is but we stan hard üò§üò§üò§üò§üò§üò§üò§üò§üò§üò§üò§üò§üò§üò§  \n1218938357918715906              @CharlotteThuil3 Mes mains sont lgbtq  \n1218938379548725249  RT @kpophappenings_: when that kpop boy played...  \n1218938380983132162  she is just your version of gun girl. you t e ...  \n1218938387857584128  RT @CTULocal1: CTU/@iftaft members! We're crea...  \n1218938389845561345  RT @fantasticleak16: Dear Twitter.You are not ...  \n1218938395017142272  @amyklobuchar Senator  I am a woman and a lesb...  \n1218938408581640192  nsfw 18+ au dom sub sugar daddy mommy lesbian ...  \n1218938410964082690  RT @DeltaAndDaisy: Today we march for women's ...  \n1218938414122373120  RT @kpophappenings_: when that kpop boy played...  \n1218938418207563786  RT @sazmeister88: if we made politics a less h...  \n1218938419608522754  RT @AFNCCF: We're asking #LGBTQ young people a...  "
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets = pd.read_csv('data/LGBTQ_no_country.csv', index_col=0, encoding='utf-8', sep=r'\\s*,\\s*', engine='python')\n",
    "tweets.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysing the polarity of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_polar = 0.\n",
    "avg_subj = 0.\n",
    "count = 0\n",
    "\n",
    "for sentence in tweets['text']:\n",
    "    blob = TextBlob(sentence)\n",
    "    count+=1\n",
    "\n",
    "    polar = blob.sentiment[0] #polarity between -1, 1\n",
    "    subj = blob.sentiment[1] #subjectivity\n",
    "    \n",
    "    avg_polar +=polar\n",
    "    avg_subj +=subj\n",
    "    \n",
    "print(\"Number of tweets analysed: \", count)\n",
    "print(\"Average polarity: \", avg_polar/count)\n",
    "print(\"Average subjectivity: \", avg_subj/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer_scores(sentence): \n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(score)))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in tweets.index: \n",
    "    tweet = tweets.loc[index, 'text']\n",
    "\n",
    "    # Detect language of tweet \n",
    "    tweets.loc[index, 'language'] = TextBlob(tweet).detect_language()\n",
    "\n",
    "    # Calculate score and write into new columns of eisting data frame\n",
    "    score = sentiment_analyzer_scores(tweet)\n",
    "    tweets.loc[index, 'polarity_neg'] = score['neg']\n",
    "    tweets.loc[index, 'polarity_neu'] = score['neu']\n",
    "    tweets.loc[index, 'polarity_pos'] = score['pos']\n",
    "    tweets.loc[index, 'polarity_compound'] = score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating a wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Create a list of word\n",
    "text = ','.join(tweets['text'].to_list())\n",
    "\n",
    "# Create a stopword list\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"http\", \"https\", \"co\", \"lgbt\", \"LGBT\", \"LGBTQ\", \"lgbtq\", \"lgbtq+\", \"LGBTQ+\", \"RT\"])\n",
    "\n",
    "# Create the wordcloud object\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    " \n",
    "# Display the generated image (matplotlib way):\n",
    "plt.figure(figsize = (10, 15))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your own analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at averages per country/region\n",
    "# Wordcloud -> keywords that are very polarised\n",
    "# Check if description contains journalist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly\n",
    "!pip install pycountry-convert\n",
    "!pip install translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc \n",
    "from googletrans import Translator\n",
    "\n",
    "translate_urls = [\"translate.google.com\", \"translate.google.co.kr\",\n",
    "                      \"translate.google.at\", \"translate.google.de\",\n",
    "                      \"translate.google.ru\", \"translate.google.ch\",\n",
    "                      \"translate.google.fr\", \"translate.google.es\"]\n",
    "\n",
    "# Translate \n",
    "translator = Translator(service_urls=translate_urls)   \n",
    "tweets['trans_country'] = [translator.translate(orig_country).text for orig_country in tweets['country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in tweets.index: \n",
    "    single_country = tweets.loc[index, 'country']\n",
    "    #tweets.head()['iso_alpha_3']\n",
    "    try:\n",
    "        country_iso_alpha_3 = pc.country_name_to_country_alpha3(single_country, cn_name_format=\"default\")\n",
    "        tweets.loc[index, 'iso_alpha_3'] = country_iso_alpha_3\n",
    "    except KeyError as e:\n",
    "        print('KeyError - reason {}'.format(str(e)))\n",
    "        tweets.loc[index, 'iso_alpha_3'] = ''\n",
    "    except IndexError as e:\n",
    "        print('I got an IndexError - reason {}'.format(str(e)))\n",
    "    except TypeError as e:\n",
    "        tweets.loc[index, 'iso_alpha_3'] = ''\n",
    "        print('I got an TypeError - reason {}'.format(str(e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "#df = px.data.gapminder().query(\"year==2007\")\n",
    "\n",
    "fig = px.choropleth(tweets.head(), \n",
    "                    locations=\"iso_alpha_3\",\n",
    "                    color=\"polarity_compound\", # lifeExp is a column of gapminder\n",
    "                    hover_name=\"country\", # column to add to hover information\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}